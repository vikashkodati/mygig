{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_TDRUtAiqzNY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikashkodati/mygig/blob/main/TwelveLabs_Quickstart_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1wq_1YvSl7jCh1P3KME96fBfJHzUSUwuo?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in  Colab</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "TYwIL79-xXQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Installation of TwelveLabs SDKs**"
      ],
      "metadata": {
        "id": "VmpYRcFNT30r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME3drNyaS-dV"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q twelvelabs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Configure your API key. Add API Key as a env variable.**\n",
        "Signup for TwelveLabs and Get your API keys [here](https://playground.twelvelabs.xyz/dashboard/api-key). No credit card is required to use the Free plan. The Free plan includes indexing of 600 mins of videos, which is enough for a small project.\n",
        "\n",
        "*To run the following cell in a*\n",
        "* *Colab Notebook, your API key must be stored it in a Colab Secret named TL_API_KEY. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [this](https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75) for an example.*\n",
        "* *In other Python environments, You can also use Python variables using `os.environ()`*\n",
        "\n"
      ],
      "metadata": {
        "id": "G47PrcTKUJEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "TL_API_KEY=userdata.get('TL_API_KEY')"
      ],
      "metadata": {
        "id": "9DBGRVboTEue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate Embeddings**\n",
        "Use the Embed API to create multimodal embeddings that are contextual vector representations for your videos and texts. Twelve Labs video embeddings capture all the subtle cues and interactions between different modalities, including the visual expressions, body language, spoken words, and the overall context of the video, encapsulating the essence of all these modalities and their interrelations over time.\n",
        "\n",
        "To create video embeddings, you must first upload your videos, and the platform must finish processing them. Uploading and processing videos require some time. Consequently, creating embeddings is an asynchronous process comprised of three steps:\n",
        "\n",
        "1. Upload and process a video: When you start uploading a video, the platform creates a video embedding task and returns its unique task identifier.\n",
        "\n",
        "2. Monitor the status of your video embedding task: Use the unique identifier of your task to check its status periodically until it's completed.\n",
        "\n",
        "3. Retrieve the embeddings: After the video embedding task is completed, retrieve the video embeddings by providing the task identifier.\n",
        "Learn more in the [docs](https://docs.twelvelabs.io/docs/create-video-embeddings)\n"
      ],
      "metadata": {
        "id": "zhXzSOCgUdmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from twelvelabs import TwelveLabs\n",
        "from typing import List\n",
        "from twelvelabs.models.embed import EmbeddingsTask, SegmentEmbedding\n",
        "\n",
        "def print_segments(segments: List[SegmentEmbedding], max_elements: int = 5):\n",
        "    for segment in segments:\n",
        "        print(\n",
        "            f\"  embedding_scope={segment.embedding_scope} start_offset_sec={segment.start_offset_sec} end_offset_sec={segment.end_offset_sec}\"\n",
        "        )\n",
        "        print(f\"  embeddings: {segment.embeddings_float[:max_elements]}\")\n",
        "\n",
        "client = TwelveLabs(api_key=TL_API_KEY)\n",
        "task = client.embed.task.create(\n",
        "    engine_name=\"Marengo-retrieval-2.6\",\n",
        "    video_url=\"https://sample-videos.com/video321/mp4/720/big_buck_bunny_720p_2mb.mp4\" # # Example: https://sample-videos.com/video321/mp4/720/big_buck_bunny_720p_2mb.mp4\n",
        ")\n",
        "print(\n",
        "    f\"Created task: id={task.id} engine_name={task.engine_name} status={task.status}\"\n",
        ")\n",
        "\n",
        "def on_task_update(task: EmbeddingsTask):\n",
        "    print(f\"  Status={task.status}\")\n",
        "\n",
        "status = task.wait_for_done(\n",
        "    sleep_interval=2,\n",
        "    callback=on_task_update\n",
        ")\n",
        "print(f\"Embedding done: {status}\")\n",
        "\n",
        "task = task.retrieve()\n",
        "if task.video_embedding is not None and task.video_embedding.segments is not None:\n",
        "    print_segments(task.video_embedding.segments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elAj0cm1Upaa",
        "outputId": "e36adf7f-fce6-4f77-d5cc-487f2016596b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created task: id=6740eaac5d3d064fe3588bb3 engine_name=Marengo-retrieval-2.6 status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=ready\n",
            "Embedding done: ready\n",
            "  embedding_scope=clip start_offset_sec=0.0 end_offset_sec=6.0\n",
            "  embeddings: [-0.060122214, 0.016685927, -0.008494042, 0.007121656, 0.0040775263]\n",
            "  embedding_scope=clip start_offset_sec=6.0 end_offset_sec=12.0\n",
            "  embeddings: [-0.05643653, 0.0128368195, 0.010626551, 0.0006593393, 0.011886367]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GET Embeddings from a video in your INDEX.**\n",
        "Replace `index_id` and `video_id` in the following code with your index and video ids.\n"
      ],
      "metadata": {
        "id": "_TDRUtAiqzNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from twelvelabs import TwelveLabs\n",
        "from typing import List\n",
        "from twelvelabs.models.embed import SegmentEmbedding\n",
        "\n",
        "def print_segments(segments: List[SegmentEmbedding], max_elements: int = 5):\n",
        "    for segment in segments:\n",
        "        print(\n",
        "            f\"  embedding_scope={segment.embedding_scope} start_offset_sec={segment.start_offset_sec} end_offset_sec={segment.end_offset_sec}\"\n",
        "        )\n",
        "        print(f\"  embeddings: {segment.embeddings_float[:max_elements]}\")\n",
        "\n",
        "client = TwelveLabs(api_key=TL_API_KEY)\n",
        "index_id = \"6733ac47f1f0c94d455e61af\" # Use your index_id\n",
        "video_id = \"6733c3481a5f2afde1139307\" # Use your video_id\n",
        "\n",
        "video = client.index.video.retrieve(\n",
        "    index_id=index_id, id=video_id, embed=True)\n",
        "if video.embedding:\n",
        "    print(f\"Engine_name={video.embedding.engine_name}\")\n",
        "    print(\"Embeddings:\")\n",
        "    print_segments(video.embedding.video_embedding.segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJopqUohqXRc",
        "outputId": "d203aa34-ebe2-43c5-a987-f510d025f3a9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engine_name=Marengo-retrieval-2.6\n",
            "Embeddings:\n",
            "  embedding_scope=clip start_offset_sec=0.0 end_offset_sec=8.833333\n",
            "  embeddings: [-0.05401685, 0.028044553, -0.006683201, 0.052161995, 0.005205433]\n",
            "  embedding_scope=clip start_offset_sec=8.866667 end_offset_sec=14.333333\n",
            "  embeddings: [-0.064734034, 0.015777389, 0.016971672, 0.06758459, -0.0042496417]\n",
            "  embedding_scope=clip start_offset_sec=14.366667 end_offset_sec=20.1\n",
            "  embeddings: [-0.04318019, 0.016767595, 0.031129684, 0.061615035, -0.033064734]\n",
            "  embedding_scope=clip start_offset_sec=20.133333 end_offset_sec=27.199999\n",
            "  embeddings: [-0.048935793, 0.0015533045, 0.04537521, 0.042919084, -0.003435039]\n",
            "  embedding_scope=clip start_offset_sec=27.233334 end_offset_sec=34.233334\n",
            "  embeddings: [-0.042636164, 0.016505633, 0.021705803, 0.060528487, -0.026437962]\n",
            "  embedding_scope=clip start_offset_sec=34.266666 end_offset_sec=41.333332\n",
            "  embeddings: [-0.03781607, 0.0047186627, 0.030991001, 0.046645194, -0.016894642]\n",
            "  embedding_scope=clip start_offset_sec=41.366665 end_offset_sec=47.0\n",
            "  embeddings: [-0.02011765, 0.010642708, 0.007128984, 0.059619643, -0.02919401]\n",
            "  embedding_scope=clip start_offset_sec=47.033333 end_offset_sec=52.666668\n",
            "  embeddings: [-0.03735479, -0.0016426818, -0.006867849, 0.056773126, -0.026588758]\n",
            "  embedding_scope=clip start_offset_sec=52.7 end_offset_sec=59.766666\n",
            "  embeddings: [-0.035139844, 0.03338483, 0.017348256, 0.04168324, 0.009212109]\n",
            "  embedding_scope=clip start_offset_sec=59.8 end_offset_sec=65.433334\n",
            "  embeddings: [-0.045430195, 0.011820866, 0.02685435, 0.028007329, -0.00657631]\n",
            "  embedding_scope=clip start_offset_sec=65.46667 end_offset_sec=71.23333\n",
            "  embeddings: [-0.03754825, 0.028669337, 0.0036057662, 0.07533823, -0.021945817]\n",
            "  embedding_scope=clip start_offset_sec=71.26666 end_offset_sec=77.566666\n",
            "  embeddings: [-0.04717382, 0.016088188, 0.037196357, 0.072151855, 0.00057445554]\n",
            "  embedding_scope=clip start_offset_sec=77.6 end_offset_sec=83.9\n",
            "  embeddings: [-0.0182887, 0.0068471613, 0.048430886, 0.022262996, -0.040964983]\n",
            "  embedding_scope=clip start_offset_sec=83.933334 end_offset_sec=91.03333\n",
            "  embeddings: [-0.019756448, 0.0011065424, 0.01981931, 0.051752757, -0.029510157]\n",
            "  embedding_scope=clip start_offset_sec=91.066666 end_offset_sec=98.799995\n",
            "  embeddings: [-0.03170779, 0.003010527, 0.02438272, 0.049629036, -0.043311752]\n",
            "  embedding_scope=clip start_offset_sec=98.833336 end_offset_sec=104.5\n",
            "  embeddings: [-0.035243068, 0.018525468, 0.016464584, 0.050573047, -0.028455045]\n",
            "  embedding_scope=clip start_offset_sec=104.53333 end_offset_sec=110.23333\n",
            "  embeddings: [-0.026270958, 0.029840069, 0.043082945, 0.033297487, 0.027280908]\n",
            "  embedding_scope=clip start_offset_sec=110.26666 end_offset_sec=117.23333\n",
            "  embeddings: [-0.029608203, -0.003653699, 0.012717048, 0.03183126, 0.038013313]\n",
            "  embedding_scope=clip start_offset_sec=117.26666 end_offset_sec=122.46667\n",
            "  embeddings: [-0.037113678, 0.00039985342, 0.03201003, 0.08695227, 0.0040678354]\n",
            "  embedding_scope=clip start_offset_sec=122.5 end_offset_sec=127.933334\n",
            "  embeddings: [-0.038288124, 0.012216642, 0.019316299, 0.06436524, -0.043043166]\n",
            "  embedding_scope=clip start_offset_sec=127.96667 end_offset_sec=133.53333\n",
            "  embeddings: [-0.03250915, 0.04258018, 0.046651058, 0.025025459, -0.039361175]\n",
            "  embedding_scope=clip start_offset_sec=133.56667 end_offset_sec=140.56667\n",
            "  embeddings: [-0.046581835, 0.018632742, 0.021175118, 0.04194331, -0.028611964]\n",
            "  embedding_scope=clip start_offset_sec=140.6 end_offset_sec=148.4\n",
            "  embeddings: [-0.05148931, 0.02642214, 0.015408829, 0.06428365, -0.031575553]\n",
            "  embedding_scope=clip start_offset_sec=148.43333 end_offset_sec=155.33333\n",
            "  embeddings: [-0.048213053, 0.024296226, 0.001808271, 0.05515464, -0.04038546]\n",
            "  embedding_scope=clip start_offset_sec=155.36667 end_offset_sec=162.53333\n",
            "  embeddings: [-0.052136153, 0.013709078, 0.0099044, 0.06687757, -0.03186632]\n",
            "  embedding_scope=clip start_offset_sec=162.56667 end_offset_sec=168.76666\n",
            "  embeddings: [-0.040493462, 0.015383309, 0.010319323, 0.0636316, -0.03796504]\n",
            "  embedding_scope=clip start_offset_sec=168.8 end_offset_sec=175.88722\n",
            "  embeddings: [-0.039319705, -0.038141634, 0.014983389, 0.032171324, 0.020645034]\n",
            "  embedding_scope=clip start_offset_sec=175.88722 end_offset_sec=182.97446\n",
            "  embeddings: [-0.056465775, -0.04935608, 0.0137964655, 0.016468214, 0.03069344]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text, Image and Audio Embeddings**"
      ],
      "metadata": {
        "id": "4cOzElBylSzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from twelvelabs import TwelveLabs\n",
        "from typing import List\n",
        "from twelvelabs.models.embed import EmbeddingsTask, SegmentEmbedding\n",
        "\n",
        "def print_segments(segments: List[SegmentEmbedding], max_elements: int = 5):\n",
        "    for segment in segments:\n",
        "        print(f\"  embeddings: {segment.embeddings_float[:max_elements]}\")\n",
        "\n",
        "def create_text_embedding(\n",
        "    twelvelabs_client: TwelveLabs,\n",
        "    text: str = \"Hello World!\",\n",
        "    engine_name: str = \"Marengo-retrieval-2.6\",\n",
        "    verbose: bool = True\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Create a text embedding using Twelve Labs Embed API.\n",
        "\n",
        "    Example:\n",
        "        twelvelabs_client = TwelveLabs(api_key=TL_API_KEY)\n",
        "        text_embedding = create_text_embedding(twelvelabs_client, \"Your text here\")\n",
        "    \"\"\"\n",
        "    # Create embedding\n",
        "    result = twelvelabs_client.embed.create(\n",
        "        engine_name=engine_name,\n",
        "        text=text\n",
        "    )\n",
        "\n",
        "    # Print information if verbose is True\n",
        "    if verbose:\n",
        "        print(\"Created a text embedding\")\n",
        "        print_segments(result.text_embedding.segments)\n",
        "\n",
        "    return result\n",
        "\n",
        "def create_audio_embedding(\n",
        "    twelvelabs_client: TwelveLabs,\n",
        "    audio_url: str = \"https://codeskulptor-demos.commondatastorage.googleapis.com/descent/background%20music.mp3\",\n",
        "    engine_name: str = \"Marengo-retrieval-2.6\",\n",
        "    verbose: bool = True\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Create an audio embedding using Twelve Labs Embed API.\n",
        "\n",
        "    Example:\n",
        "        twelvelabs_client = TwelveLabs(api_key=TL_API_KEY)\n",
        "        audio_embedding = create_audio_embedding(twelvelabs_client, \"path/to/audio.mp3\")\n",
        "    \"\"\"\n",
        "    # Create embedding\n",
        "    result = twelvelabs_client.embed.create(\n",
        "        engine_name=engine_name,\n",
        "        audio_url=audio_url,\n",
        "    )\n",
        "\n",
        "    # Print information if verbose is True\n",
        "    if verbose:\n",
        "        print(\"Created an audio embedding\")\n",
        "        if result.audio_embedding.segments:\n",
        "            print_segments(result.audio_embedding.segments)\n",
        "\n",
        "    return result\n",
        "\n",
        "def create_image_embedding(\n",
        "    twelvelabs_client: TwelveLabs,\n",
        "    image_url:  str = \"https://gratisography.com/wp-content/uploads/2024/01/gratisography-cyber-kitty-1170x780.jpg\",\n",
        "    engine_name: str = \"Marengo-retrieval-2.6\",\n",
        "    verbose: bool = True\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Create an image embedding using Twelve Labs Embed API.\n",
        "\n",
        "    Example:\n",
        "        twelvelabs_client = TwelveLabs(api_key=TL_API_KEY)\n",
        "        image_embedding = create_image_embedding(twelvelabs_client, \"path/to/image.jpg\")\n",
        "    \"\"\"\n",
        "    # Create embedding\n",
        "    result = twelvelabs_client.embed.create(\n",
        "        engine_name=engine_name,\n",
        "        image_url=image_url\n",
        "    )\n",
        "\n",
        "    # Print information if verbose is True\n",
        "    if verbose:\n",
        "        print(\"Created an image embedding\")\n",
        "        if result.image_embedding.segments:\n",
        "            print_segments(result.image_embedding.segments)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "_CckrUFflQgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from twelvelabs import TwelveLabs\n",
        "from typing import List\n",
        "from twelvelabs.models.embed import EmbeddingsTask, SegmentEmbedding\n",
        "\n",
        "twelvelabs_client = TwelveLabs(api_key=TL_API_KEY)\n",
        "\n",
        "aem = create_audio_embedding(twelvelabs_client)\n",
        "im = create_image_embedding(twelvelabs_client)\n",
        "tm = create_text_embedding(twelvelabs_client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlV-_2Nkm196",
        "outputId": "4fc7758e-4f0e-45ff-dc0f-1bc2a3d3637f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created an audio embedding\n",
            "  embeddings: [-0.07128955, 0.010958959, 0.01905033, -0.013187495, 0.068803824]\n",
            "Created an image embedding\n",
            "  embeddings: [-0.03812987, 0.013206651, 0.016828481, 0.06474987, 0.007665184]\n",
            "Created a text embedding\n",
            "  embeddings: [0.061489083, 0.020508073, -0.039171655, -0.004987218, 0.015630098]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N8IK7EZojUxs"
      }
    }
  ]
}